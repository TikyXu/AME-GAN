{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from einops import rearrange, repeat, pack, unpack\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# device_dis = torch.device('cuda:0')\n",
    "# device_gen = torch.device('cuda:0')\n",
    "\n",
    "# 获取当前日期和时间\n",
    "run_time = datetime.now()\n",
    "model_kind = f'Inversely-proportional_Generation'\n",
    "\n",
    "save_path = os.path.join(f'ablation_study_results', str(run_time))\n",
    "save_path = os.path.join(save_path, model_kind)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(f'{save_path}', exist_ok=True)\n",
    "os.makedirs(f'{save_path}/models', exist_ok=True)\n",
    "os.makedirs(f'{save_path}/results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_UNSWNB15(path_train_data, path_test_data, binary_or_multi='multi'):\n",
    "\n",
    "    categorical_columns = ['proto', 'service', 'state']\n",
    "    \n",
    "    classification = ['Normal', 'Fuzzers', 'Analysis', 'Backdoor', 'DoS', \n",
    "                    'Exploits', 'Generic', 'Reconnaissance', 'Shellcode', 'Worms']\n",
    "    # 加载数据 train_num:125973, test_num:22544, total_data:148517\n",
    "    data_train = pd.read_csv(path_train_data).copy()\n",
    "    data_test = pd.read_csv(path_test_data).copy()\n",
    "    total_data = pd.concat([data_train, data_test], axis=0) # 合并train和test\n",
    "    total_data = total_data.drop(['id'], axis=1)\n",
    "    train_num = len(data_train)\n",
    "    test_num = len(data_test)\n",
    "\n",
    "    # 特征\n",
    "    features = total_data.iloc[:, :-2]     \n",
    "    \n",
    "    # 标签（以Binary/Multi形式加载Y的值）\n",
    "    if binary_or_multi=='binary':    \n",
    "        # 删除attack_cat列\n",
    "        total_data = total_data.drop('attack_cat', axis=1)\n",
    "        # 把labels转换为binary[0,1] \n",
    "        labels = total_data.iloc[:, -1]\n",
    "    elif binary_or_multi=='multi':\n",
    "        # 删除label列\n",
    "        total_data = total_data.drop('label', axis=1)\n",
    "        labels_class = total_data.iloc[:, -1]\n",
    "        \n",
    "        pdlist_class_dict = {}\n",
    "        for index, data_class in enumerate(classification):\n",
    "            pdlist_class_dict[data_class] = index\n",
    "                \n",
    "        labels = np.array([pdlist_class_dict[row] for row in np.array(labels_class)])\n",
    "        \n",
    "    # One-hot编码数据\n",
    "    features = pd.get_dummies(features, columns=categorical_columns)\n",
    "    \n",
    "    # Min-Max标准化\n",
    "    scaler = MinMaxScaler().fit(features)\n",
    "    features = scaler.transform(features)\n",
    "\n",
    "    # 凑形状，增加60列\n",
    "    addition_number = 60\n",
    "    addition_data = np.zeros((len(total_data), addition_number))\n",
    "    features = np.concatenate((features, addition_data), axis=1)\n",
    "    \n",
    "    # X_train = features[:train_num][:, :, np.newaxis]\n",
    "    # X_test = features[train_num:][:, :, np.newaxis]\n",
    "    X_train = features[:train_num].astype(np.float32)\n",
    "    X_test = features[train_num:].astype(np.float32)\n",
    "    Y_train = labels[:train_num].astype(np.longlong)\n",
    "    Y_test = labels[train_num:].astype(np.longlong)\n",
    "    \n",
    "        \n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_train = torch.LongTensor(Y_train)\n",
    "    Y_test = torch.LongTensor(Y_test)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_classes, dim, dropout):\n",
    "        super().__init__()\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.Linear(dim, num_classes),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp_head(x)\n",
    "    \n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, *, seq_len, patch_size, dim, channels, emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        assert (seq_len % patch_size) == 0\n",
    "\n",
    "        num_patches = seq_len // patch_size\n",
    "        patch_dim = channels * patch_size\n",
    "        # patch_dim = patch_size\n",
    "        self.patch_dim = [patch_size, channels, patch_dim]\n",
    "        \n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (n p) -> b n (p c)', p = patch_size),\n",
    "            # batch_size channels (patch_number * patch_size) -> batch_size patch_number (patch_size * channels)\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "    def forward(self, series):\n",
    "        x = self.to_patch_embedding(series)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, 'd -> b d', b = b)\n",
    "        \n",
    "        x, ps = pack([cls_tokens, x], 'b * d')\n",
    "\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x, ps\n",
    "    \n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "                \n",
    "        self.to_qkv1 = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_qkv2 = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        qkv1 = self.to_qkv1(x).chunk(3, dim = -1)\n",
    "        _, k1, v1 = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv1)\n",
    "\n",
    "        qkv2 = self.to_qkv2(y).chunk(3, dim = -1)\n",
    "        q2, _, _ = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv2)\n",
    "        \n",
    "        dots = torch.matmul(q2, k1.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v1)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, lstm_hidden_dim=64, lstm_layers=2, dropout=0.1):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_dim, lstm_hidden_dim, num_layers=lstm_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.embedding = nn.Linear(lstm_hidden_dim*2, input_dim)\n",
    "        \n",
    "        self.mlp = MultiLayerPerceptron(dim=input_dim,\n",
    "                                        num_classes=num_classes,\n",
    "                                        dropout=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM部分\n",
    "        x, _ = self.bilstm(x)  # x: (batch_size, seq_length, input_dim)\n",
    "        x = x[:, -1, :]  # 取最后一个时间步的输出作为特征\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        y = self.mlp(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTransformer(nn.Module):    \n",
    "    def __init__(self, input_dim, num_classes, lstm_hidden_dim=64, lstm_layers=2, nhead=4, dim_feedforward=128, num_layers=6, dropout=0.1):\n",
    "        super(BiLSTMTransformer, self).__init__()\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_dim, lstm_hidden_dim, num_layers=lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(lstm_hidden_dim*2, int(input_dim/2))\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=int(input_dim/2), nhead=nhead, dim_feedforward=int(input_dim/2), dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        self.mlp = MultiLayerPerceptron(dim=int(input_dim/2),\n",
    "                                        num_classes=num_classes,\n",
    "                                        dropout=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM部分\n",
    "        x, _ = self.bilstm(x)  # x: (batch_size, seq_length, input_dim)\n",
    "        x = x[:, -1, :]  # 取最后一个时间步的输出作为特征\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = self.transformer_encoder(x).squeeze(1)\n",
    "\n",
    "        y = self.mlp(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +Inversely-proportional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTransformerGenerator(nn.Module):    \n",
    "    def __init__(self, z_dim, input_dim, num_classes, lstm_hidden_dim=64, lstm_layers=2, nhead=4, dim_feedforward=128, num_layers=6, dropout=0.1):\n",
    "        super(BiLSTMTransformerGenerator, self).__init__()\n",
    "        # Generator\n",
    "        self.input_noise = nn.Sequential(nn.Linear(z_dim, input_dim),\n",
    "                                         nn.LayerNorm(input_dim))\n",
    "        \n",
    "        self.input_label = nn.Sequential(nn.Linear(num_classes, input_dim),            \n",
    "                                         nn.LayerNorm(input_dim))\n",
    "        \n",
    "        self.multiheadcrossattention = MultiHeadCrossAttention(dim=input_dim, \n",
    "                                                               heads=nhead, \n",
    "                                                               dim_head = int(input_dim/nhead), \n",
    "                                                               dropout = dropout)\n",
    "\n",
    "        self.bilstm = nn.LSTM(input_dim, lstm_hidden_dim, num_layers=lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(lstm_hidden_dim*2, int(input_dim/2))\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=int(input_dim/2), nhead=nhead, dim_feedforward=int(input_dim/2), dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        self.mlp = MultiLayerPerceptron(dim=int(input_dim/2),\n",
    "                                        num_classes=input_dim,\n",
    "                                        dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        noise = self.input_noise(x)\n",
    "        label = self.input_label(y)\n",
    "\n",
    "        mhca = self.multiheadcrossattention(noise, label)\n",
    "\n",
    "        # LSTM部分\n",
    "        x, _ = self.bilstm(mhca)  # x: (batch_size, seq_length, input_dim)\n",
    "        x = x[:, -1, :]  # 取最后一个时间步的输出作为特征\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = self.transformer_encoder(x).squeeze(1)\n",
    "\n",
    "        y = self.mlp(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数、模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoches = 30\n",
    "batch_size=256\n",
    "last_epoch = -1\n",
    "print_interval = 100\n",
    "\n",
    "input_dim = 256\n",
    "z_dim = 100\n",
    "class_num = 10\n",
    "lstm_layers = 2\n",
    "nhead = 4\n",
    "tb_layers = 6\n",
    "dropout = 0.1\n",
    "\n",
    "# model = BiLSTM(input_dim=input_dim, \n",
    "#                num_classes=class_num, \n",
    "#                lstm_hidden_dim=input_dim, \n",
    "#                lstm_layers=lstm_layers,\n",
    "#                dropout=dropout).to(torch.device(\"cuda\"))\n",
    "\n",
    "dis = BiLSTMTransformer(\n",
    "                          input_dim=input_dim, \n",
    "                          num_classes=class_num, \n",
    "                          lstm_hidden_dim=input_dim, \n",
    "                          lstm_layers=lstm_layers, \n",
    "                          nhead=nhead, \n",
    "                          dim_feedforward=input_dim, \n",
    "                          num_layers=tb_layers, \n",
    "                          dropout=dropout\n",
    "                        ).to(torch.device(\"cuda\"))\n",
    "\n",
    "gen = BiLSTMTransformerGenerator(\n",
    "                          z_dim=z_dim,\n",
    "                          input_dim=input_dim, \n",
    "                          num_classes=class_num, \n",
    "                          lstm_hidden_dim=input_dim, \n",
    "                          lstm_layers=lstm_layers, \n",
    "                          nhead=nhead, \n",
    "                          dim_feedforward=input_dim, \n",
    "                          num_layers=tb_layers, \n",
    "                          dropout=dropout\n",
    "                        ).to(torch.device(\"cuda\"))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_dis = Adam(params=dis.parameters(), lr=1e-3)\n",
    "optimizer_gen = Adam(params=gen.parameters(), lr=1e-3)\n",
    "scheduler_dis = CosineAnnealingLR(optimizer_dis, T_max=train_epoches, last_epoch=last_epoch)\n",
    "scheduler_gen = CosineAnnealingLR(optimizer_gen, T_max=train_epoches, last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data='datasets/UNSW-NB15/UNSW_NB15_training-set.csv'\n",
    "path_test_data='datasets/UNSW-NB15/UNSW_NB15_testing-set.csv'\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = Load_UNSWNB15(path_train_data=path_train_data, \n",
    "                                                 path_test_data=path_test_data, \n",
    "                                                 binary_or_multi='multi')# 装载数据到loader里面\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "class_number_count = pd.DataFrame(Y_train).value_counts().values # 训练集数据Value Counts\n",
    "class_ratio = [item/sum(class_number_count) for item in class_number_count] # 训练集数据各类占比\n",
    "minus_log = [-math.log(item) for item in class_ratio] # 计算各类的倒数自然对数\n",
    "invert_ratio = [log/sum(minus_log) for log in minus_log] # 计算各类的反比\n",
    "\n",
    "def _weighted_random_int():\n",
    "    total = sum(invert_ratio)\n",
    "    r = random.uniform(0, total)\n",
    "    s = 0\n",
    "    for i, w in enumerate(invert_ratio):\n",
    "        s += w\n",
    "        if r < s:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accu = 0\n",
    "best_epoch = 0\n",
    "for epo in range(train_epoches):\n",
    "    print(f'Training Epoch{epo+1}')    \n",
    "    \n",
    "    for index, (train_image, train_label) in enumerate(train_loader):\n",
    "        train_image, train_label = train_image.view(train_image.shape[0], -1, train_image.shape[1]).cuda(non_blocking=True), train_label.to(torch.int64).cuda(non_blocking=True)\n",
    "        train_label = torch.nn.functional.one_hot(train_label, class_num).to(torch.float32).cuda(non_blocking=True)\n",
    "        optimizer_dis.zero_grad()\n",
    "        #############\n",
    "        # 训练判别器\n",
    "        #############\n",
    "        dis.train()\n",
    "        outs_real = dis(train_image).view(train_label.shape)        \n",
    "        dis_loss = criterion(outs_real, train_label)\n",
    "\n",
    "        dis_loss.backward()\n",
    "        optimizer_dis.step()\n",
    "        scheduler_dis.step()\n",
    "\n",
    "        #############\n",
    "        # 训练生成器\n",
    "        #############\n",
    "        gen.train()\n",
    "        # dis.eval()\n",
    "        # 生成噪声\n",
    "        noise = torch.randn(train_image.shape[0], 1, z_dim).cuda(non_blocking=True)\n",
    "        \n",
    "        # 生成反比例标签\n",
    "        inversely_label = np.array([_weighted_random_int() for i in range(train_image.shape[0])])\n",
    "        fake_label = torch.from_numpy(inversely_label).to(int).cuda(non_blocking=True)\n",
    "        fake_label_one_hot = nn.functional.one_hot(fake_label, num_classes=class_num).to(torch.float32).view(train_image.shape[0], 1, -1).cuda(non_blocking=True)\n",
    "            \n",
    "        fake_sample = gen(noise, fake_label_one_hot).unsqueeze(1)\n",
    "        # with torch.no_grad():\n",
    "        #     generate_outs = dis(fake_sample).view(train_label.shape)\n",
    "        generate_outs = dis(fake_sample).view(train_label.shape)\n",
    "        gen_loss = criterion(generate_outs, fake_label_one_hot.squeeze(1))\n",
    "        gen_loss.backward()\n",
    "        optimizer_gen.step()\n",
    "        scheduler_gen.step()\n",
    "        \n",
    "        \n",
    "        accuracy = accuracy_score(torch.argmax(outs_real, dim=1).cpu(), torch.argmax(train_label, dim=1).cpu())\n",
    "        if (index % print_interval) == 0 and index != 0:\n",
    "            print(f'Epo{epo}/Iter{index} - Accu:{accuracy}')\n",
    "\n",
    "    dis.eval()    \n",
    "    Y_pred = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    ground_truth = np.array([])\n",
    "    for image, label in test_loader:\n",
    "        Y_test = np.append(Y_test, label, axis=None)\n",
    "        image, label = image.view(image.shape[0], -1, image.shape[1]).cuda(non_blocking=True), label.cuda(non_blocking=True)\n",
    "\n",
    "        predicted = dis(image).view(label.shape[0], -1)\n",
    "        predicted = torch.argmax(predicted, dim=1)\n",
    "        \n",
    "        Y_pred = np.append(Y_pred, predicted.cpu().numpy(), axis=None)\n",
    "            \n",
    "    accuracy_test = accuracy_score(Y_test, Y_pred)\n",
    "    \n",
    "    if accuracy_test > best_accu:\n",
    "        best_accu = accuracy_test\n",
    "        best_epoch = epo\n",
    "        best_pred = Y_pred\n",
    "        ground_truth = Y_test\n",
    "        \n",
    "        #保存整个模型\n",
    "        torch.save(dis, f'{save_path}/models/{model_kind}_{epo}_accu_{accuracy_test:.4f}.pth')\n",
    "        np.save(f'{save_path}/models/best_pred_accu_{accuracy_test:.4f}.npy', best_pred)\n",
    "        np.save(f'{save_path}/models/ground_truth_accu_{accuracy_test:.4f}.npy', ground_truth)\n",
    "        \n",
    "    print_lines = f'Epoch {epo+1}/{train_epoches}:\\nAccuracy:{accuracy_test}\\n'\n",
    "    print_lines += f'Best Accuracy:{best_accu} - Epoch:{best_epoch+1}\\n'\n",
    "    print(print_lines)\n",
    "    \n",
    "    with open(f'{save_path}/results/{model_kind}_Multi.txt', 'a', encoding='utf-8') as file:\n",
    "        # 将输出内容写入文件\n",
    "        file.write(print_lines+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
